---
title: "Account Closure Analysis"
output: pdf_document
---


**Your Name**: Yueying Wang
**Your G Number**: G01062022

## Add R libraries here
```{r}
library(tidyverse)
library(tidymodels)
library(discrim)
library(klaR)
library(kknn)
library(magrittr)
library(dplyr)
library(ggplot2)
library(vip)
```

```{r message=FALSE, warning=FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)


credit_card_df <- readRDS(url('https://gmubusinessanalytics.netlify.app/data/credit_card_df.rds'))
credit_card_df
```



# Data Analysis

In this section, you must think of at least 5 relevant questions that explore the relationship between `customer_status` and the other variables in the `credit_card_df` data set. The goal of your analysis should be discovering which variables drive the differences between customers who do and do not close their account.

You must answer each question and provide supporting data summaries with either a summary data frame (using `dplyr`/`tidyr`) or a plot (using `ggplot`) or both.

In total, you must have a minimum of 3 plots (created with `ggplot`) and 3 summary data frames (created with `dplyr`) for the exploratory data analysis section. Among the plots you produce, you must have at least 3 different types (ex. box plot, bar chart, histogram, scatter plot, etc...)

See the [Data Analysis Project](https://gmubusinessanalytics.netlify.app/data-analysis-project.html){target="_blank"} for an example of a question answered with a summary table and plot.

**Note**: To add an R code chunk to any section of your project, you can use the keyboard shortcut `Ctrl` + `Alt` + `i` or the `insert` button at the top of your R project template notebook file.



# Question 1


**Question**:

Is there a relationship between spend_ratio and customer status?

**Answer**:
Yes, from the data below we can see that people who did not close the account have higher spend_ratio with the card (around 0.77) than people who closed the account which is around 0.69. Additionally, when we look at the box plot we can clear see even though the average spending ratios are very close, the maximum and minimum have very a big difference. People who did not close the account minimum spend ratio is 0.256 compared to ratio 0 that people who did close the account. And the maximum spend ratio on people who did not close the account is 2.282 compared to ratio 1.492 of people who did close the account.

```{r}

credit_card_data <- credit_card_df %>%
  add_column(Closed_Account = if_else(.$customer_status == "closed_account", "YES", "NO"))

credit_card_data %>% group_by(Closed_Account) %>% 
                  summarise(n_customer = n(),
                            min_spend_ratio = min(spend_ratio_q4_q1),
                            max_spend_ratio = max(spend_ratio_q4_q1),
                            avg_spend_ratio = mean(spend_ratio_q4_q1))
                  

```
### Data Visulatization
```{r}
ggplot(credit_card_data, aes(x = Closed_Account , y = spend_ratio_q4_q1,fill = Closed_Account)) +
  geom_boxplot() +
  scale_y_log10() +ggtitle("Spend Ratio Vs.Customer status")

```



# Question 2


**Question**:

Is there a relationship between employment status and customer status?

**Answer**:
Yes, from the plot below we can see that there is a strong relationship between employment status and customer status.The customer who has employment status part-time is more likely to close the account. People who have employment status of full-time and self-employed are more willing to keep the account. 

```{r}

ggplot(credit_card_data, aes(x = Closed_Account, fill = employment_status)) + 
  geom_bar(color="Black") +
  labs(x = "Closed Account",
       y = "Number of Entries",
       title = "Closed Account VS. Employment Status", fill = 'employment_status') +
  coord_flip()

```


# Question 3


**Question**:

Are there relationships between months_since_first_account and months_inactive_last_year with customer status?
 
**Answer**:

Yes, there is a relationship between months_inactive_last_year with customer status. From the data below, we can see that customers are willing to close the account if the average number of months inactive last year is higher. But there is a very small impact on the relationship between months_since_first_account with customer status. From the data below, we can see that the average months since the first account between closed accounts and active accounts are almost the same. 

```{r}



credit_card_data %>% group_by(Closed_Account)%>%                 
                            summarise(n_Customer = n(),
                            avg_months_since_first_account = mean(months_since_first_account),
                            avg_months_inactive_last_year = mean(months_inactive_last_year)) 

```

```{r}
ggplot(credit_card_data, aes(x = months_inactive_last_year,fill = Closed_Account)) + 
  geom_bar(color="Black")+ 
  labs(x = "months_inactive_last_year",
       y = "Number of Entries",
       title = "Closed Account VS. Months Inactive Last Year", fill = 'Closed_Account')
  

```

# Question 4


**Question**:
Is there a relationship between transaction ratio and customer status?

**Answer**:
Yes, from the data below we can see that the customer who has a lower transaction ratio will be more likely to close the account. The average transaction ratio for customers who stays active is 0.74, and the average transaction ratio for customers who closed accounts is 0.56. Therefore, the company needs to improve service of the customer that has a transaction ratio of less than 0.74. 


```{r}


credit_card_data %>% group_by(Closed_Account) %>% 
                  summarise(n_customer = n(),
                            min_transaction_ratio = min(transaction_ratio_q4_q1),
                            max_transaction_ratio = max(transaction_ratio_q4_q1),
                            avg_transaction_ratio = mean(transaction_ratio_q4_q1),
                            avg_total_spend_last_year = mean(total_spend_last_year))
                  

```

```{r}
ggplot(credit_card_data, aes(x = transaction_ratio_q4_q1,fill = Closed_Account)) + 
  geom_histogram(bins = 30)+ 
  labs(x = "Transaction Ratior",
       y = "Number of Entries",
       title = "Closed Account VS. Transaction Ratio", fill = 'Closed_Account')
  

```



# Question 5


**Question**:

Is there a relationship between card type and customer status?

**Answer**:
Yes, from the data below we can see that the customers who have a blue card are more likely to close the account (more than 400 blue card customers chose to close account compared to a customer who stays active based on customer number on 2500 scale), and over half of customers who hold the silver card and gold card are more willing to stay. 


```{r}
credit_card_data_type <-credit_card_data %>%
group_by(card_type,Closed_Account) %>%
summarize(n_customer = n(),
          mean_utilization_ratio = mean(utilization_ratio),
          mean_spend_ratio = mean(spend_ratio_q4_q1),
          mean_transaction_ratio = mean(transaction_ratio_q4_q1))
credit_card_data_type 
```
```{r}
ggplot(credit_card_data, aes(x = Closed_Account, fill = 	card_type)) + 
  geom_bar(color="Black") +
  labs(x = "Closed Account",
       y = "Number of Entries",
       title = "Closed Account VS. Card Type", fill = 'card_type')


```




# Machine Learning


In this section of the project, you will fit **three classification algorithms** to predict the outcome variable,`customer_status`.

You must follow the machine learning steps below. 

The data splitting and feature engineering steps should only be done once so that your models are using the same data and feature engineering steps for training.

- Split the `credit_card_df` data into a training and test set (remember to set your seed)
- Specify a feature engineering pipeline with the `recipes` package
    - You can include steps such as skewness transformation, correlation filters, dummy variable encoding or any other steps you find appropriate
- Specify a `parsnip` model object
    - You may choose from the following classification algorithms:
      - Logistic Regression
      - LDA
      - QDA
      - KNN
      - Decision Tree
      - Random Forest
- Package your recipe and model into a workflow
- Fit your workflow to the training data
    - If your model has hyperparameters:
      - Split the training data into 5 folds for 5-fold cross validation using `vfold_cv` (remember to set your seed)
      - Perform hyperparamter tuning with a random grid search using the `grid_random()` function
      - Refer to the following tutorial for an example - [Random Grid Search](https://gmubusinessanalytics.netlify.app/lesson-08-r-tutorial.html#Hyperparameter_Tuning14){target="_blank"}
      - Hyperparameter tuning can take a significant amount of computing time. Be careful not to set the `size` argument of `grid_random()` too large. I recommend `size` = 10 or smaller.
      - Select the best model with `select_best()` and finalize your workflow
- Evaluate model performance on the test set by plotting an ROC curve using `autoplot()` and calculating the area under the ROC curve on your test data


## Data Splitting

We will split the data into a training and test set. The training data will be further divided into 5 folds for hyperparameter tuning.



```{r}

set.seed(314) 

cc_split <- initial_split(credit_card_df  , prop = 0.75, 
                             strata = customer_status)

cc_training <- cc_split %>% training()

cc_test <- cc_split %>% testing()

# Create folds for cross validation on the training data set
## These will be used to tune model hyperparameters
set.seed(314)

cc_folds <- vfold_cv(cc_training, v = 5)

```
## Feature Engineering
```{r}

cc_recipe <- recipe(customer_status ~ ., data = cc_training) %>% 
                       step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                       step_normalize(all_numeric(), -all_outcomes()) %>% 
                       step_dummy(all_nominal(), -all_outcomes())
```
Let's check to see if the feature engineering steps have been carried out correctly.

```{r}

cc_recipe %>% 
  prep(training = cc_training) %>% 
  bake(new_data = NULL)
```
# Model 1 Decision Tree

```{r}
tree_model <- decision_tree(cost_complexity = tune(),
                            tree_depth = tune(),
                            min_n = tune()) %>% 
              set_engine('rpart') %>% 
              set_mode('classification')

```
## Workflow

```{r}

tree_workflow <- workflow() %>% 
                 add_model(tree_model) %>% 
                 add_recipe(cc_recipe)
```

## Hyperparameter Tuning
```{r}

## Create a grid of hyperparameter values to test
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)
```


```{r}
# View grid
tree_grid

tree_grid <- grid_regular(parameters(tree_model), 
                          levels = 2)
tree_grid
```
### Tuning Hyperparameters with `tune_grid()`
```{r}

## Tune decision tree workflow
set.seed(314)

tree_tuning <- tree_workflow %>% 
               tune_grid(resamples = cc_folds,
                         grid = tree_grid)
```

```{r}

## Show the top 5 best models based on roc_auc metric
tree_tuning %>% show_best('roc_auc')
```

```{r}

## Select best model based on roc_auc
best_tree <- tree_tuning %>% 
             select_best(metric = 'roc_auc')

# View the best tree parameters
best_tree
```
### Finalize Workflow
```{r}

final_tree_workflow <- tree_workflow %>% 
                       finalize_workflow(best_tree)
```

## Visualize Results
```{r}

tree_wf_fit <- final_tree_workflow %>% 
               fit(data = cc_training)

tree_fit <- tree_wf_fit %>% 
            extract_fit_parsnip()

vip(tree_fit)

```

### Decision Tree Plot

```{r fig.height = 8, fig.width = 11}
library(rpart.plot)
rpart.plot(tree_fit$fit, roundint = FALSE)
```

```{r}

tree_last_fit <- final_tree_workflow %>% 
                 last_fit(cc_split)

tree_last_fit %>% collect_metrics()
```
### ROC Curve 


```{r}

tree_last_fit %>% collect_predictions() %>% 
                  roc_curve(truth  = customer_status, estimate = .pred_closed_account) %>% 
                  autoplot()
```



### Confusion Matrix

We see that our model made 40 false negatives and 34 false positives on our test data set.

```{r}

tree_predictions <- tree_last_fit %>% collect_predictions()

conf_mat(tree_predictions, truth = customer_status, estimate = .pred_class)
```




# Model 2 Regression Model

```{r}
# Create cross validation folds for hyperparameter tuning
set.seed(314)

cc_folds <- vfold_cv(cc_training, v = 10)

# Feature Engineering

cc_recipe <- recipe(customer_status ~ ., data = cc_training) %>% 
                 step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                 step_normalize(all_numeric(), -all_outcomes()) %>% 
                 step_dummy(all_nominal(), -all_outcomes())

# Feature Engineering
cc_recipe %>% 
  prep(training = cc_training) %>% 
  bake(new_data = NULL)

# Specify Logistic Regression Model
logistic_model <- logistic_reg() %>% 
                  set_engine('glm') %>% 
                  set_mode('classification')

# Create a Workflow
logistic_wf <- workflow() %>% 
               add_model(logistic_model) %>% 
               add_recipe(cc_recipe)
# Fit Model
logistic_fit <- logistic_wf %>% 
                last_fit(split = cc_split)

# Collect Predictions

logistic_results <-  logistic_fit %>% 
                     collect_predictions()

roc_curve(logistic_results, 
          truth = customer_status, 
          estimate = .pred_closed_account) %>% 
  autoplot()

# ROC AUC
roc_auc(logistic_results, 
        truth = customer_status,
        .pred_closed_account)
# Confusion Matrix
conf_mat(logistic_results, 
         truth = customer_status, 
         estimate = .pred_class)


```


# Model 3 Specify LDA model
```{r}
lda_model <- discrim_regularized(frac_common_cov = 1) %>% 
             set_engine('klaR') %>% 
             set_mode('classification')

lda_wf <- workflow() %>% 
          add_model(lda_model) %>% 
          add_recipe(cc_recipe)

lda_fit <- lda_wf %>% 
           last_fit(split = cc_split)

lda_results <-  lda_fit %>% 
                collect_predictions()

roc_curve(lda_results, 
          truth = customer_status, 
          estimate = .pred_closed_account) %>% 
  autoplot()

roc_auc(lda_results, 
        truth = customer_status, 
        .pred_closed_account)

conf_mat(lda_results, 
         truth = customer_status, 
         estimate = .pred_class)


model <- glm( customer_status ~., data = credit_card_df, family = binomial)
tidymodel <- tidy(model)
summary(model)

vip(model)
```




# Summary of Results

Write a summary of your overall findings and recommendations to the executives at the bank. Think of this section as your closing remarks of a presentation, where you summarize your key findings, model performance, and make recommendations to improve customer retention and service at the bank.

Your executive summary must be written in a [professional tone](https://www.universalclass.com/articles/writing/business-writing/appropriate-tone-in-business-communications.htm){target="_blank"}, with minimal grammatical errors, and should include the following sections:

1. An introduction where you explain the business problem and goals of your data analysis

    - What problem(s) is this company trying to solve? Why are they important to their future success?
    
    
  
    - What was the goal of your analysis? What questions were you trying to answer and why do they matter?


2. Highlights and key findings from your Exploratory Data Analysis section 
    - What were the interesting findings from your analysis and **why are they important for the business**?

    - This section is meant to **establish the need for your recommendations** in the following section


3. Your “best” classification model and an analysis of its performance 
    - In this section you should talk about the expected error of your model on future data
      - To estimate future performance, you can use your model performance results on the **test data**
    - You should discuss at least one performance metric, such as an F1, sensitivity, specificity, or ROC AUC for your model. However, you must explain the results in an **intuitive, non-technical manner**. Your audience in this case are executives at a telecommunications company with limited knowledge of machine learning.


4. Your recommendations to the company on how to reduce customer attrition rates 
  
    - Each recommendation must be supported by your data analysis results 

    - You must clearly explain why you are making each recommendation and which results from your data analysis support this recommendation

    - You must also describe the potential business impact of your recommendation:
      
      - Why is this a good recommendation? 
      
      - What benefits will the business achieve?


**Summary**
Add your summary here. Please do not place your text within R code chunks.

1. An introduction where you explain the business problem and goals of your data analysis

This company is trying to find out the reason why people closed their credit card account. It is very important because the business can improve their weakness/business strategies to keep the clients in business, so the bank can make more profit. My goal for this project is to help this company find the key reason and provide useful suggestions to help to reduce the rate of customer lose. 

2, Highlights and key findings from your Exploratory Data Analysis section.

Here are some highlights and key findings from my analysis. First, based on the average spend ratio for people who closed the account is 0.69 lower than people who kept the account 0.77 . The average total spent last year for people who closed the account is around \$3121 and the average total spend last year for people who did not close the account is around \$4597. Second, avg_transaction_ratio is a key factor for customer status. As we can see that the avg_transaction_ratio for people who closed the account is 0.56 it is much less than the number of people who kept the account 0.74. Third, the relationship between customer status and card_type, according to the number I have, more than half of people that hold a blue card closed their account, and they all have low utilization ratio, spend ratio, and transaction ratio. More than half of the people that hold silver and gold cards chose to stay active.

3, Your “best” classification model and an analysis of its performance

I have built a Decision Tree, Logistic Regression, and LDA model to find the most significant factors by using ROC AUC to measure the accuracy of the model. The most accurate model has a higher ROC AUC to find the factors that have the most serious impact on credit card closure. The ROC AUC of the Decision Tree model is 94.41677%, The ROC AUC of the Logistic Regression model is 93.60128%. The ROC AUC of the LDA model is 93.4915%. Therefore, the Decision Tree model is the best model. There are also some significant factors that have arisen from this model. As we can tell from the VIP function, there are 4 factors that affect users in closing their account. The 4 factors include total_spend_last_year, transactions_last_year, transaction_ratio_q4_q1, and utilization_ratio. Among the 4 factors, total_spend_last_year and transactions_last_year are the most important factors.

4,Your recommendations to the company on how to reduce customer attrition rates
Based on the Decision Tree model and the analysis I did on the dataset, here are some recommendations to the bank on how to reduce customer account closure rate.

(1). total_spend_last_year and transactions_last_year are the most important factors based on the Decision Tree model. Combining the decision tree model and the analysis we did, the average total amount for customers who did not close the account is around \$4600, and the average total amount for customers who did close the account is around $3100. So I suggest that the company should offer a promotion that applies to the level of spend amount during the year. for example, the customer who spends more than 5k a year in travel and restaurants will reward a personal gift and free upgraded card.

(2). transaction_ratio is another important factor that is a strong relationship between 
customer status and transaction_ratio.  From the analysis above we know that people who are more frequently using the card are less likely to close the account.  The average transaction ratio is around 0.74 for customers who did not close account, so the company needs to find the customers that have lower transaction ratio than 0.74 to encourage them to use the card more often. The bank can offer more reward points, shopping discounts, etc to those customers. 

(3). Employee status is a very important factor as well. From the analysis above we see that customers whose employment status is part-time is more likely to close the account. So the bank should focus on these customers, by offering a credit card that has a bigger reward point system on essential need transactions such as grocery shopping, restaurants, and gas. On the other hand, the bank also needs to improve the service of the customer who has employment status on full-time and self-employed to keep them to stable, by offering a credit card that has exclusive service such as personal concierge program, access to airport VIP lounges, complimentary memberships on cooperative merchants, etc.

(4). Card type is the key factor to customer status that I found in the analysis. As I mentioned before, the customer who has a blue card is more likely to close the account and the customer who holds the silver card and gold card is more willing to stay. The data shows in a 2500 scale blue card type customer, almost 1500 customers closed the account which is around 58%, and compared to silver and gold card type, the account closure rate is 25% and 32%. That’s a huge difference! The company needs to inform the customer by sending an email to encourage blue cardholders to upgrade their card to silver levels.  
